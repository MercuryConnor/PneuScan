{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required libraries if not already installed\n",
        "import sys\n",
        "import subprocess\n",
        "\n",
        "def install_if_missing(packages):\n",
        "    for package in packages:\n",
        "        try:\n",
        "            __import__(package)\n",
        "        except ImportError:\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "\n",
        "install_if_missing([\"numpy\", \"pandas\", \"matplotlib\", \"seaborn\", \"tensorflow\", \"torch\", \"torchvision\", \"scikit-learn\", \"opencv-python\", \"kaggle\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "import cv2\n",
        "\n",
        "DATASET_PATH = r\"E:\\Projects\\PneuScan\\chest_xray\"\n",
        "if os.path.exists(DATASET_PATH):\n",
        "    print(\"Dataset found ✅\")\n",
        "    print(\"Contents:\", os.listdir(DATASET_PATH))\n",
        "else:\n",
        "    print(\"❌ Dataset not found. Check the path!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data loading and preprocessing pipeline\n",
        "labels = ['NORMAL', 'PNEUMONIA']  # NORMAL=0, PNEUMONIA=1\n",
        "\n",
        "def get_images_and_labels(data_dir, img_size=150):\n",
        "    images, labels_list = [], []\n",
        "    class_names = ['NORMAL', 'PNEUMONIA']\n",
        "    for i, label in enumerate(class_names):\n",
        "        path = os.path.join(data_dir, label)\n",
        "        if not os.path.isdir(path):\n",
        "            continue\n",
        "        for img_name in os.listdir(path):\n",
        "            try:\n",
        "                img_path = os.path.join(path, img_name)\n",
        "                img_arr = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "                if img_arr is None:\n",
        "                    continue\n",
        "                img_resized = cv2.resize(img_arr, (img_size, img_size))\n",
        "                images.append(img_resized)\n",
        "                labels_list.append(i)\n",
        "            except Exception:\n",
        "                continue\n",
        "    return np.array(images), np.array(labels_list)\n",
        "\n",
        "# Load all data\n",
        "train_images, train_labels = get_images_and_labels(os.path.join(DATASET_PATH, 'train'))\n",
        "test_images, test_labels = get_images_and_labels(os.path.join(DATASET_PATH, 'test'))\n",
        "val_images, val_labels = get_images_and_labels(os.path.join(DATASET_PATH, 'valid'))\n",
        "\n",
        "# Combine and split for robust test/val/train\n",
        "all_images = np.concatenate([train_images, test_images, val_images], axis=0)\n",
        "all_labels = np.concatenate([train_labels, test_labels, val_labels], axis=0)\n",
        "\n",
        "x_temp, x_test, y_temp, y_test = train_test_split(all_images, all_labels, test_size=0.2, random_state=42, stratify=all_labels)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_temp, y_temp, test_size=0.2, random_state=42, stratify=y_temp)\n",
        "\n",
        "# Normalize and reshape\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_val = x_val.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "x_train = x_train.reshape(-1, 150, 150, 1)\n",
        "x_val = x_val.reshape(-1, 150, 150, 1)\n",
        "x_test = x_test.reshape(-1, 150, 150, 1)\n",
        "\n",
        "print(f\"Train: {x_train.shape}, Val: {x_val.shape}, Test: {x_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Data Generators for MobileNetV2 (224x224 RGB) ---\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    'chest_xray/train',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    color_mode='rgb',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_generator = train_datagen.flow_from_directory(\n",
        "    'chest_xray/train',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    color_mode='rgb',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# --- Save the trained model ---\n",
        "model.save('best_pneumonia_model.h5')\n",
        "print('Model saved as best_pneumonia_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute class weights\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
        "print(\"Class weights:\", class_weights_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model definition\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 1), padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPool2D(pool_size=(2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPool2D(pool_size=(2, 2)),\n",
        "    Dropout(0.2),\n",
        "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPool2D(pool_size=(2, 2)),\n",
        "    Dropout(0.2),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Callbacks\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "callbacks = [\n",
        "    ModelCheckpoint('best_pneumonia_model.h5', monitor='val_loss', save_best_only=True, mode='min', verbose=1),\n",
        "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=1)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Lightweight Model: MobileNetV2 Transfer Learning ---\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Input, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Commented out original custom CNN model for reference\n",
        "'''\n",
        "model = Sequential([\n",
        "    Conv2D(...),\n",
        "    MaxPooling2D(...),\n",
        "    # ... more layers ...\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "'''\n",
        "\n",
        "\n",
        "# MobileNetV2 as feature extractor\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "base_model.trainable = False  # Freeze base for initial training\n",
        "\n",
        "inputs = Input(shape=(224, 224, 3))\n",
        "x = base_model(inputs, training=False)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.2)(x)  # Optional: helps regularization\n",
        "outputs = Dense(1, activation='sigmoid')(x)\n",
        "model = Model(inputs, outputs)\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Note: Make sure your data generators/loaders resize images to 224x224 and use 3 channels (RGB)\n",
        "\n",
        "# --- Training the Model ---\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n",
        "    ModelCheckpoint('best_pneumonia_model.h5', save_best_only=True)\n",
        "]\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=10,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "# --- Save the trained model (best weights already saved by ModelCheckpoint) ---\n",
        "print('Model training complete. Best model saved as best_pneumonia_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model evaluation\n",
        "results = model.evaluate(x_test, y_test)\n",
        "y_pred_prob = model.predict(x_test)\n",
        "y_pred = (y_pred_prob > 0.5).astype(int)\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['NORMAL', 'PNEUMONIA']))\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training and validation curves\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Train Acc')\n",
        "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
        "plt.title('Accuracy')\n",
        "plt.legend()\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "plt.title('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize some predictions\n",
        "indices = np.random.choice(range(len(y_test)), 6, replace=False)\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i, idx in enumerate(indices):\n",
        "    plt.subplot(2, 3, i+1)\n",
        "    img = x_test[idx].squeeze()\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    color = 'green' if y_test[idx] == y_pred[idx] else 'red'\n",
        "    true_label = 'PNEUMONIA' if y_test[idx] == 1 else 'NORMAL'\n",
        "    pred_label = 'PNEUMONIA' if y_pred[idx] == 1 else 'NORMAL'\n",
        "    plt.title(f\"True: {true_label}\\nPred: {pred_label}\", color=color)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "print(tf.keras.__version__)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "GPUT",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
